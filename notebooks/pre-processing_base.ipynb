{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_cleaning_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/gus/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"rslp\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"tweet_text\", \"sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura de dados brutos (~700k tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"../data/raw/NoThemeTweets.csv\", delimiter = \",\", usecols = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.drop_duplicates([\"tweet_text\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de 70.000 tweets de forma pseudo aleatória para poupar custo computacional, as proporções de tweets positivos e negativos são mantidas.\n",
    "#### Essa será a nossa base de dados reduzida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df_raw.loc[df_raw.sentiment==\"Positivo\", :]\n",
    "df_negative = df_raw.loc[df_raw.sentiment==\"Negativo\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df_positive.sample(35000, random_state=42);\n",
    "df_negative = df_negative.sample(35000, random_state=42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.concat([df_positive, df_negative], ignore_index=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positivo    35000\n",
       "Negativo    35000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação de funções para remover links, nomes de usuários dos tweets e caracteres especiais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"tweet_text\"] = df_raw[\"tweet_text\"].apply(\n",
    "    lambda tweet: formatar_texto(texto=tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"tweet_text\"] = df_raw[\"tweet_text\"].apply(\n",
    "    lambda tweet: remove_special_chars(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção dos emojis dos textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"tweet_text\"] = df_raw[\"tweet_text\"].apply(\n",
    "    lambda tweet: demoji.replace(tweet, \"\")); # custoso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicação de função para etiquetar os sentimentos positivos com o valor 1 e negativos com o valor 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw[\"sentiment\"] = df_raw[\"sentiment\"].replace({\"Positivo\": 1, \"Negativo\": 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando uma coluna com o número de palavras por tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.assign(\n",
    "    number_words=df_raw.tweet_text.apply(lambda x: len(x.split(\" \"))),\n",
    ")  # adiciona coluna com número de palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção dos tweets que possuem menos de 5 palavras. Esses tweets curtos podem vir a atrapalhar a etapa de modelagem e portanto serão excluídos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_df_raw = df_raw.drop(\n",
    "    df_raw[df_raw.number_words < 5].index\n",
    ")  # remove tweets com menos de 5 palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remoção da coluna coluna number_words que não é mais necessária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_df_raw.drop([\"number_words\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_raw # liberando espaço na memória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 2 - Geração de 4 DataFrames a partir da remoção ou não das Stopwords, e aplicação de Stemming ou Lematização. \n",
    "### DataFrame 1: sem Stopwords e Lematizado; \n",
    "### DataFrame 2 : sem Stopwords e com Stemming; \n",
    "### DataFrame 3: com Stopwords e Lematizado;\n",
    "### DataFrame 4: com Stopwords e com Stimming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/Pipeline formatação de texto.png\" width=auto heigth=auto>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_steamed_no_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_steamed_no_stopwords[\"tweet_text\"] = df_no_stopwords[\"tweet_text\"].apply(\n",
    "    lambda tweet: stemming(texto=tweet)\n",
    ")\n",
    "\n",
    "df_lemmetized_no_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_lemmetized_no_stopwords[\"tweet_text\"] = df_no_stopwords[\"tweet_text\"].apply(\n",
    "    lambda tweet: lematization(tweet)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checagem do DataFrame lematizado sem a remoção das stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capaz q bom q pude ajudar com algo d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>esse serviria para moderar o debate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o quantidade de cpf cancelar em 2019 ser Imens...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>otimo eu tbm vo de samus fazer um 4x só de samus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>não ter nada para fazer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>só poder ser tu reclamar de si mesmo ser que n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ar a contar o dia para eu ir embora e em o últ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cf outside nebraska e danny oi esperar que gos...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sigar maratona de prison Break até de manhã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>oi ufpi estar oficialmente de volta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_text  sentiment\n",
       "0                capaz q bom q pude ajudar com algo d          1\n",
       "2                 esse serviria para moderar o debate          1\n",
       "3   o quantidade de cpf cancelar em 2019 ser Imens...          1\n",
       "5    otimo eu tbm vo de samus fazer um 4x só de samus          1\n",
       "6                             não ter nada para fazer          1\n",
       "7   só poder ser tu reclamar de si mesmo ser que n...          1\n",
       "8   ar a contar o dia para eu ir embora e em o últ...          1\n",
       "9   cf outside nebraska e danny oi esperar que gos...          1\n",
       "10        sigar maratona de prison Break até de manhã          1\n",
       "11                oi ufpi estar oficialmente de volta          1"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmetized_no_stopwords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checagem do DataFrame com stemming sem a remoção das stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capaz q bom q pud ajud com alg d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ess serv par moder o debat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a quant de cpf cancel em 2019 ser imens cheg a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>otim eu tbm vo de samu faz um 4x só de samu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>não tenh nad par faz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>só pod ser tu reclam de si mesm send que nunc ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and a cont os dia par me ir emb e no últ dia a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cf outsid nebrask e danny oi esper que gost ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sig maraton de prison break até de manhã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>oi ufp est ofic de volt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_text  sentiment\n",
       "0                    capaz q bom q pud ajud com alg d          1\n",
       "2                          ess serv par moder o debat          1\n",
       "3   a quant de cpf cancel em 2019 ser imens cheg a...          1\n",
       "5         otim eu tbm vo de samu faz um 4x só de samu          1\n",
       "6                                não tenh nad par faz          1\n",
       "7   só pod ser tu reclam de si mesm send que nunc ...          1\n",
       "8   and a cont os dia par me ir emb e no últ dia a...          1\n",
       "9   cf outsid nebrask e danny oi esper que gost ab...          1\n",
       "10           sig maraton de prison break até de manhã          1\n",
       "11                            oi ufp est ofic de volt          1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_steamed_no_stopwords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura das stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = pd.read_csv(\"../data/processed/stopwords.csv\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remoção das stopwords e aplicação de Lematização e stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_with_stopwords[\"tweet_text\"] = df_with_stopwords[\"tweet_text\"].apply(\n",
    "    lambda tweet: remover_stop_words(tweet, stopwords)\n",
    ")\n",
    "\n",
    "df_steamed_with_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_steamed_with_stopwords[\"tweet_text\"] = df_with_stopwords[\"tweet_text\"].apply(\n",
    "    lambda tweet: stemming(texto=tweet)\n",
    ")\n",
    "\n",
    "df_lemmetized_with_stopwords = formated_df_raw.copy()\n",
    "\n",
    "df_lemmetized_with_stopwords[\"tweet_text\"] = df_with_stopwords[\"tweet_text\"].apply(\n",
    "    lambda tweet: lematization(tweet)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checagem do DataFrame com stemming e com remoção das stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capaz q bom q pud ajud alg d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>serv moder debat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quant cpf cancel 2019 imens cheg saliv p</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>otim tbm vo samu faz 4x samu</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nad faz</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pod ser reclam si send nunc problem p</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>and cont dia ir emb últ dia ador diz dest está...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cf outsid nebrask danny oi esper gost abr cap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sig maraton prison break manhã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>oi ufp ofic volt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_text  sentiment\n",
       "0                        capaz q bom q pud ajud alg d          1\n",
       "2                                    serv moder debat          1\n",
       "3            quant cpf cancel 2019 imens cheg saliv p          1\n",
       "5                        otim tbm vo samu faz 4x samu          1\n",
       "6                                             nad faz          1\n",
       "7               pod ser reclam si send nunc problem p          1\n",
       "8   and cont dia ir emb últ dia ador diz dest está...          1\n",
       "9   cf outsid nebrask danny oi esper gost abr cap ...          1\n",
       "10                     sig maraton prison break manhã          1\n",
       "11                                   oi ufp ofic volt          1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_steamed_with_stopwords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checagem do dataframe lematizado e com remoção de stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>capaz q bom q pude ajudar algo d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>servir moderar debate</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quantidade cpf cancelar 2019 imensar chego sal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>otimo tbm vo samus fazer 4x samus</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nada fazer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>poder ser reclamar se ser nunca problema p</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ar contar dias ir embora último dia adorar diz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cf outside nebraska danny oi esperar goste abr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sigar maratona prison break manhã</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>oi ufpi oficialmente voltar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_text  sentiment\n",
       "0                    capaz q bom q pude ajudar algo d          1\n",
       "2                               servir moderar debate          1\n",
       "3   quantidade cpf cancelar 2019 imensar chego sal...          1\n",
       "5                   otimo tbm vo samus fazer 4x samus          1\n",
       "6                                          nada fazer          1\n",
       "7          poder ser reclamar se ser nunca problema p          1\n",
       "8   ar contar dias ir embora último dia adorar diz...          1\n",
       "9   cf outside nebraska danny oi esperar goste abr...          1\n",
       "10                  sigar maratona prison break manhã          1\n",
       "11                        oi ufpi oficialmente voltar          1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lemmetized_with_stopwords.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkagem da integridade do dados processados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57966, 2) (57966, 2) (57966, 2) (57966, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_steamed_no_stopwords.shape,df_lemmetized_no_stopwords.shape,df_steamed_with_stopwords.shape,df_lemmetized_with_stopwords.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando os DataFrames na pasta data/processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_steamed_no_stopwords.to_csv('../data/processed/df_steamed_no_stopwords.csv', index=False)\n",
    "df_lemmetized_no_stopwords.to_csv('../data/processed/df_lemmetized_no_stopwords.csv', index=False)\n",
    "df_steamed_with_stopwords.to_csv('../data/processed/df_steamed_with_stopwords.csv', index=False)\n",
    "df_lemmetized_with_stopwords.to_csv('../data/processed/df_lemmetized_with_stopwords.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_lemmetized_no_stopwords.csv\t  df_steamed_no_stopwords.csv\n",
      "df_lemmetized_with_stopwords.csv  df_steamed_with_stopwords.csv\n"
     ]
    }
   ],
   "source": [
    "!ls ../data/processed/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "882c8c6501720d7339a894262ca6c76e47c685bc126574a2b14e77f6df77b0f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
